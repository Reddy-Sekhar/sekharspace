{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Reddy-Sekhar/sekharspace/blob/main/textsummarizer_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vp0mBgmTD3p7"
   },
   "outputs": [],
   "source": [
    "!pip install transformers[sentencepiece] datasets sacrebleu rouge_score py7zr -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pItVmEJDD2eY",
    "outputId": "405889cc-e196-4ad1-bbb3-f5223b2d338a"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade accelerate\n",
    "!pip uninstall -y transformers accelerate\n",
    "!pip install transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XdDzkg_DBG8A",
    "outputId": "0e0c42d6-ad32-4d66-d01e-7e4ec4c962aa"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "\n",
    "nltk.download(\"punkt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1GSVUru4HtTo"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "iR1_-iX3gnAl",
    "outputId": "ba67f9b8-0721-4d89-dd7e-b514e603202c"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "dPLnSnnTgq9U",
    "outputId": "47094066-18d1-419e-e897-0645e83ebe7f"
   },
   "outputs": [],
   "source": [
    "'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GwJpd3TPgtlG"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gX-4plhDgygd",
    "outputId": "6c598d27-f72a-4e29-cf6f-1d85627faf78"
   },
   "outputs": [],
   "source": [
    "model_ckpt = \"google/pegasus-cnn_dailymail\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C3ifIQq7g4qx",
    "outputId": "17206ad6-cf74-4b31-ae69-8ab4d0cf5b1b"
   },
   "outputs": [],
   "source": [
    "model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NxJUHpEqg4t2"
   },
   "outputs": [],
   "source": [
    "dataset_samsum = load_dataset(\"samsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "teMXGrOWg4wp",
    "outputId": "c5b02cda-3d20-467d-8f4b-f25a238d7c78"
   },
   "outputs": [],
   "source": [
    "dataset_samsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "U3Wv_p9Ng4zn",
    "outputId": "68a2e52f-2118-4eee-aa02-8c78027fa5b9"
   },
   "outputs": [],
   "source": [
    "dataset_samsum[\"train\"][\"dialogue\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "-4sZkCxeg42h",
    "outputId": "0d73037d-a106-449e-d1b9-318227810480"
   },
   "outputs": [],
   "source": [
    "dataset_samsum[\"train\"][1][\"summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Si7LGbZXg45I",
    "outputId": "12deeca3-b102-440f-ff2c-af6d31c8296a"
   },
   "outputs": [],
   "source": [
    "split_lengths = [len(dataset_samsum[split])for split in dataset_samsum]\n",
    "\n",
    "print(f\"Split lengths: {split_lengths}\")\n",
    "print(f\"Features: {dataset_samsum['train'].column_names}\")\n",
    "print(\"\\nDialogue:\")\n",
    "\n",
    "print(dataset_samsum[\"test\"][1][\"dialogue\"])\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "\n",
    "print(dataset_samsum[\"test\"][1][\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5RX1hjc-g47W"
   },
   "outputs": [],
   "source": [
    "def convert_examples_to_features(example_batch):\n",
    "    input_encodings = tokenizer(example_batch['dialogue'] , max_length = 1024, truncation = True )\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        target_encodings = tokenizer(example_batch['summary'], max_length = 128, truncation = True )\n",
    "\n",
    "    return {\n",
    "        'input_ids' : input_encodings['input_ids'],\n",
    "        'attention_mask': input_encodings['attention_mask'],\n",
    "        'labels': target_encodings['input_ids']\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "a399b9ab46274957bb8f40dd137c2abf",
      "679a663be83744a3b63fb33d9f11d363",
      "97dd5c351dd44d4cbd16d9669b764b19",
      "fea0f318555b437788998dfd821ba841",
      "63613d5b906c46c9ab494a6397729ee6",
      "073d7f0f60724e91b3c3bec7c7a949e0",
      "6df7afd1092444a195236f0e35a04752",
      "b57f9503f4cd48c0a7116db339e7c91e",
      "48531ea9489e44da9ae83c265b18218e",
      "96b111bb64214e07904f695151651c15",
      "ca0d67b3248f4554a038f966bc2944a3"
     ]
    },
    "id": "QCSF1eM2hNhc",
    "outputId": "38d108d0-7147-4c65-e265-61b4abedf20b"
   },
   "outputs": [],
   "source": [
    "dataset_samsum_pt = dataset_samsum.map(convert_examples_to_features, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JW1mWRZ-hNkC",
    "outputId": "4d807078-b5fb-4bbc-ec35-f885bcd32cbd"
   },
   "outputs": [],
   "source": [
    "dataset_samsum_pt[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVp3hB0QhNm5",
    "outputId": "f7bde81f-1b73-411b-b2a0-5a897e1ce673"
   },
   "outputs": [],
   "source": [
    "dataset_samsum_pt[\"train\"][\"input_ids\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dg_-pp4DhNpz",
    "outputId": "18b3550a-14b7-4061-b19f-c92b1c046080"
   },
   "outputs": [],
   "source": [
    "dataset_samsum_pt[\"train\"][\"attention_mask\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "flh8DBv2hNss"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model_pegasus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rdx7VeeUhNvq",
    "outputId": "d7c1e19c-d570-4321-f0d1-1e210ab34959"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "trainer_args = TrainingArguments(\n",
    "    output_dir='pegasus-samsum', num_train_epochs=1, warmup_steps=500,\n",
    "    per_device_train_batch_size=1, per_device_eval_batch_size=1,\n",
    "    weight_decay=0.01, logging_steps=10,\n",
    "    evaluation_strategy='steps', eval_steps=500, save_steps=1e6,\n",
    "    gradient_accumulation_steps=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SSV9fnVwheRZ",
    "outputId": "59de37f1-8e91-4029-bc2b-ff2857dbe812"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model_pegasus, args=trainer_args,\n",
    "                  tokenizer=tokenizer, data_collator=seq2seq_data_collator,\n",
    "                  train_dataset=dataset_samsum_pt[\"test\"],\n",
    "                  eval_dataset=dataset_samsum_pt[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "id": "79LPjwX0heUE",
    "outputId": "970f24e3-3008-4954-9442-136cbb0a0c6b"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jy57FzsEheYk"
   },
   "outputs": [],
   "source": [
    "def generate_batch_sized_chunks(list_of_elements, batch_size):\n",
    "    for i in range(0, len(list_of_elements), batch_size):\n",
    "        yield list_of_elements[i : i + batch_size]\n",
    "\n",
    "\n",
    "\n",
    "def calculate_metric_on_test_ds(dataset, metric, model, tokenizer,\n",
    "                               batch_size=16, device=device,\n",
    "                               column_text=\"article\",\n",
    "                               column_summary=\"highlights\"):\n",
    "    article_batches = list(generate_batch_sized_chunks(dataset[column_text], batch_size))\n",
    "    target_batches = list(generate_batch_sized_chunks(dataset[column_summary], batch_size))\n",
    "\n",
    "    for article_batch, target_batch in tqdm(\n",
    "        zip(article_batches, target_batches), total=len(article_batches)):\n",
    "\n",
    "        inputs = tokenizer(article_batch, max_length=1024,  truncation=True,\n",
    "                        padding=\"max_length\", return_tensors=\"pt\")\n",
    "\n",
    "        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
    "                         attention_mask=inputs[\"attention_mask\"].to(device),\n",
    "                         length_penalty=0.8, num_beams=8, max_length=128)\n",
    "\n",
    "        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n",
    "                                clean_up_tokenization_spaces=True)\n",
    "               for s in summaries]\n",
    "\n",
    "        decoded_summaries = [d.replace(\"\", \" \") for d in decoded_summaries]\n",
    "\n",
    "\n",
    "        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
    "\n",
    "    score = metric.compute()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "id": "YQxEdkYhheb3",
    "outputId": "e7a7c518-6e9f-483e-b8dd-eb04267a8f49"
   },
   "outputs": [],
   "source": [
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "rouge_metric = load_metric('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "W6jFBPbzhefu",
    "outputId": "05ab9ee0-10d8-47b6-fb5e-2764a8b08db1"
   },
   "outputs": [],
   "source": [
    "score = calculate_metric_on_test_ds(\n",
    "    dataset_samsum['test'][0:10], rouge_metric, trainer.model, tokenizer, batch_size = 2, column_text = 'dialogue', column_summary= 'summary'\n",
    ")\n",
    "\n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure ) for rn in rouge_names )\n",
    "\n",
    "pd.DataFrame(rouge_dict, index = [f'pegasus'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ukkNBkrIhejb",
    "outputId": "e0ddd95c-9023-44dd-b760-f0ba98014c78"
   },
   "outputs": [],
   "source": [
    "model_pegasus.save_pretrained(\"pegasus-samsum-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BwPtDUG2hemt",
    "outputId": "d7ba91c2-8885-4763-b5a8-d4a498e24d0f"
   },
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(\"tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleIA2Q7heqE"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"/content/tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fGJxcr_2hetV"
   },
   "outputs": [],
   "source": [
    "gen_kwargs = {\"length_penalty\": 0.8, \"num_beams\":8, \"max_length\": 128}\n",
    "\n",
    "\n",
    "\n",
    "sample_text = dataset_samsum[\"test\"][0][\"dialogue\"]\n",
    "\n",
    "reference = dataset_samsum[\"test\"][0][\"summary\"]\n",
    "\n",
    "pipe = pipeline(\"summarization\", model=\"pegasus-samsum-model\",tokenizer=tokenizer)\n",
    "\n",
    "##\n",
    "print(\"Dialogue:\")\n",
    "print(sample_text)\n",
    "\n",
    "\n",
    "print(\"\\nReference Summary:\")\n",
    "print(reference)\n",
    "\n",
    "\n",
    "print(\"\\nModel Summary:\")\n",
    "print(pipe(sample_text, **gen_kwargs)[0][\"summary_text\"])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPKdUehOAi+prAXPNIMkWx1",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
